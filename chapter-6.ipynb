{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Interview: Model Deployment and End-to-End ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data\n",
    "- How would you collect training data and evaluate the risks? (Refer to Chapter 4.)\n",
    "\n",
    "### Feature engineering\n",
    "- How would you come up with relevant features for the ML task? (Refer to Chapter 4.)\n",
    "\n",
    "### Modeling\n",
    "- How do you justify choosing a specific model? Explain the training process, and explain the risks and how you’d mitigate them. (Refer to Chapters 3 and 4.)\n",
    "\n",
    "### Evaluation and deployment\n",
    "- How do you evaluate and deploy the model? How do you justify which metrics to monitor? (Refer to Chapters 4 and 6.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interview question 6-1: Can you walk through an example where you improved the scalability of ML infrastructure?\n",
    "\n",
    "- Using scaling on Kubernetes helped; for example, horizontal scaling helped distribute the same workload across more instances. In cases when the heavy load came from request volume, I used load balancing with the Google Kubernetes Engine. In the past, I’ve used autoscaling features in cloud platforms, such as when I was working with GCP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interview question 6-2: How do you handle the monitoring and performance tracking of ML models in production?\n",
    "- For machine learning, I’ve learned that what’s different between monitoring an ML application in production as opposed to an application without ML is the data and model-related monitoring. This includes monitoring for data drift, model accuracy and drifts, and so on. For this, I use tools such as Great Expectations or Alibi Detect. In particular, at my previous company we used Great Expectations to check for sudden large amounts of missing values or distribution shifts.\n",
    "- In addition, using those monitoring tools, I can create alerts and have recurring anomaly-detection jobs on those platforms to report errors or drifts. On the service availability side (more general, less ML specific), tools such as Grafana, ELK Stack (Elasticsearch, Logstash, and Kibana, aka Elastic Stack), and Prometheus are commonly used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
